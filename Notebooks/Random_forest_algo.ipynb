{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39660084",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3de3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 2. Interaction Features\n",
    "def create_interaction_features(df):\n",
    "    \"\"\"Create interaction features from the student performance dataset\"\"\"\n",
    "    \n",
    "    # Copy the dataframe to avoid modifying the original\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Parent-Study interaction: How parental support might amplify study effectiveness\n",
    "    df_new['ParentStudyInteraction'] = df_new['ParentalSupport'] * df_new['StudyTimeWeekly']\n",
    "    \n",
    "    # Extracurricular intensity: Sum of all activity participations\n",
    "    df_new['ExtracurricularIntensity'] = df_new['Sports'] + df_new['Music'] + df_new['Volunteering']\n",
    "    \n",
    "    # Academic involvement intensity: Combines study time and tutoring\n",
    "    df_new['AcademicInvolvement'] = df_new['StudyTimeWeekly'] * (1 + 0.5 * df_new['Tutoring']) #Add explanation!\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# 3. Ratio and Aggregate Features\n",
    "def create_ratio_aggregate_features(df):\n",
    "    \"\"\"Create ratio and aggregate features from the student performance dataset\"\"\"\n",
    "    \n",
    "    # Copy the dataframe to avoid modifying the original\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Study efficiency: ratio of study time to absences (with handling for zero absences)\n",
    "    df_new['StudyEfficiency'] = df_new['StudyTimeWeekly'] / (df_new['Absences'] + 1)\n",
    "    \n",
    "    # Academic balance: ratio of study time to extracurricular activities\n",
    "    extracurricular_count = df_new[['Sports', 'Music', 'Volunteering']].sum(axis=1)\n",
    "    # Adding 1 to avoid division by zero\n",
    "    df_new['AcademicBalance'] = df_new['StudyTimeWeekly'] / (extracurricular_count + 1)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Combined function to apply both feature engineering techniques\n",
    "def engineer_features(df):\n",
    "    \"\"\"Apply both interaction and ratio/aggregate feature engineering\"\"\"\n",
    "    df = create_interaction_features(df)\n",
    "    df = create_ratio_aggregate_features(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0b5b3",
   "metadata": {},
   "source": [
    "## Random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "\n",
    "df = pd.read_csv('Student_performance_prepped_data.csv')\n",
    "\n",
    "df_engineered = engineer_features(df)\n",
    "\n",
    "# Define feature set and target\n",
    "X = df_engineered.drop('GradeClass', axis=1)\n",
    "y = df_engineered['GradeClass']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter grid (In order tO better the accuracy of the model)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200], # Number of trees in the forest; 100 and 200 chose for balance between performance and computation that is needed\n",
    "    'max_depth': [10, 20], # Maximum depth of each tree; 10 and 20 limit complexity to prevent overfitting\n",
    "}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    rf, # Base model with fixed random seed\n",
    "    param_grid=param_grid, # Hyperparameter grid to search over\n",
    "    cv=5, #Give us good cross validation number as it will allow for 240 fits (10 folds) without taking too much time to execute\n",
    "    scoring='accuracy', # Use accuracy as the metric to optimize\n",
    "    n_jobs=-1 # Use all available CPU cores to increase the speed of execution of the algorithm\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f3199",
   "metadata": {},
   "source": [
    "## Analyzing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37aca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 10, 'n_estimators': 200}\n",
      "\n",
      "Accuracy: 0.9214046822742475\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.41      0.58        27\n",
      "         1.0       0.86      0.84      0.85        67\n",
      "         2.0       0.89      0.96      0.92        98\n",
      "         3.0       0.90      0.91      0.91       103\n",
      "         4.0       0.95      0.98      0.96       303\n",
      "\n",
      "    accuracy                           0.92       598\n",
      "   macro avg       0.92      0.82      0.84       598\n",
      "weighted avg       0.92      0.92      0.92       598\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     Feature  Importance\n",
      "11                       GPA    0.525864\n",
      "4                   Absences    0.181040\n",
      "15           StudyEfficiency    0.082008\n",
      "14       AcademicInvolvement    0.036607\n",
      "3            StudyTimeWeekly    0.033765\n",
      "12    ParentStudyInteraction    0.033432\n",
      "16           AcademicBalance    0.031594\n",
      "6            ParentalSupport    0.014667\n",
      "13  ExtracurricularIntensity    0.011877\n",
      "2          ParentalEducation    0.010467\n",
      "\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model Parameters (the hyperparameters that were applied)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Save the model results\n",
    "results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'feature_importance': importance_df\n",
    "}\n",
    "\n",
    "# Export results to CSV\n",
    "importance_df.to_csv('feature_importance_random_forest_algo.csv', index=False)\n",
    "\n",
    "print(\"\\nModel training and evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ec96f",
   "metadata": {},
   "source": [
    "# Explanation of the results\n",
    "\n",
    "## Best parameters explanation:\n",
    "  * `max_depth: 10`: Limits tree depth of each tree to 10 branches to prevent overfitting trees.\n",
    "   * `n_estimators: 200`: The number of trees, although this increases the execution time of the model, it does allow for a more accurate prediction.\n",
    "\n",
    "## Accuracy explanation:\n",
    " * Overall accuracy is **92.14%**, which however the accuracy is further explored in the classification report.\n",
    "\n",
    "## Classification report explanation:\n",
    "   The classification report provides precision, recall, f1-score, and support for each class. \n",
    "\n",
    "   * **Class 0.0**:\n",
    "     * **Explanation:**: The model struggles to identify class 0.0 instances (indicated by the recall value of 41% and the f1-score of 58%), likely due to the low amount of data points that are present to train and test the model on (only 27 data points are available as indicated by the support ). This is not a huge issue as this class is the top performance students thus a high accuracy here is not the biggest concern.\n",
    "\n",
    "   * **Class 1.0**\n",
    "     * **Explanation:**: Reasonable performance in all metrics, as the model had an accuracy of **85%** as indicated by the **f1 score**\n",
    "\n",
    "   * **Class 2.0 AND 3.0**:\n",
    "     * **Explanation:**: The model preforms relatively the same with both these models, with high recall (**96% for class 2.0** and **0.91 for class 3.0**) suggesting itâ€™s reliable for identifying class in these classes this is also indicated by **f1 score of 92% in class 2.0 and 91% in class 3.0**.\n",
    "\n",
    "\n",
    "   * **Class 4.0**:\n",
    "     * **Explanation:**: The model preforms the best here, likely due to the large number of samples. This is also the most important class to be accurate in as this class indicates the problem students. Having a high accuracy here is very beneficial.\n",
    "\n",
    "## The Top 10 most important features \n",
    "This shows what features has the greatest effect on the target variable (Grade class).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55368a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

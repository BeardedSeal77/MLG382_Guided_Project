{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc02c99f",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f3714",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 1) Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3389096",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "# pip install tensorflow\n",
    "# pip install keras\n",
    "# pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22161cf",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 2) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Data/Student_performance_scaled.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5629a",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 3) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e01d6",
   "metadata": {},
   "source": [
    "#### i) Encoding Categorical Variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df):\n",
    "    # all features are already scaled, so return unchanged.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d8f1b",
   "metadata": {},
   "source": [
    "#### ii) Ratio & Aggregate Features: \n",
    "\n",
    "adds new features in the for of ratios\n",
    "\n",
    "`StudyAbsenceRatio` combines `StudyTimeWeekly` and `Absences`. ↑study:↓absent = ↑ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f895d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ratio-based feature(s)\n",
    "def add_ratio_features(df):\n",
    "    df = df.copy()\n",
    "    # Study Time to Absence ratio\n",
    "    df['StudyAbsenceRatio'] = df['StudyTimeWeekly'] / (df['Absences'] + 1)  # +1 to avoid division by zero\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee7a7f",
   "metadata": {},
   "source": [
    "#### iii) Interaction Features:\n",
    "\n",
    "adds new features in terms of interaction\n",
    "\n",
    "`SportsMusic` multiplies `Sports` and `Music` to give an understanding into the total extra carricular activities a student takes part in\n",
    "\n",
    "`TotalSupport` adds `TotalSupport` and `Tutoring` to show total support given to a student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "    # Combining sports and music participation\n",
    "    df['SportsMusic'] = df['Sports'] * df['Music']\n",
    "    # Combined parental involvement\n",
    "    df['TotalSupport'] = df['ParentalSupport'] + df['Tutoring']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a5234",
   "metadata": {},
   "source": [
    "#### iV) Apply all feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e87446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_engineering(df):\n",
    "    df = encode_categorical_features(df)\n",
    "    df = add_ratio_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9846f05",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 4) Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c3ce2",
   "metadata": {},
   "source": [
    "`x` = features (independent variables the model learns from).\n",
    "\n",
    "`y` = target (GradeClass, the label we want the model to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "df = apply_feature_engineering(df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['GradeClass'], axis=1)\n",
    "y = df['GradeClass']\n",
    "\n",
    "# Split the data into train and test sets (ensure y_test is defined)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b8c8a",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 5) Build model and set up tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d0e66",
   "metadata": {},
   "source": [
    "using the sequential keras model\n",
    "\n",
    "Model: https://keras.io/api/models/sequential/\n",
    "\n",
    "Explained: https://www.geeksforgeeks.org/keras-sequential-class/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units1', min_value=32, max_value=256, step=32), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(units=hp.Int('units2', min_value=32, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(5, activation='softmax'))  # 5 classes for GradeClass\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce6b23",
   "metadata": {},
   "source": [
    "keras tuner:\n",
    "\n",
    "https://keras.io/keras_tuner/api/tuners/random/\n",
    "\n",
    "automatically searches for the best hyperparameters for the deep learning model instead of using a grid or manual methods.\n",
    "\n",
    "It works by:\n",
    "1) Randomly picks different combinations of settings.\n",
    "2) Trains a model with each.\n",
    "3) Picks the best based on a metric specified (`objective` = `'val_accuracy'`).\n",
    "\n",
    "Settings it tries in the script:\n",
    "\n",
    "`units1`, `units2`: Neurons in 1st and 2nd layers (32 to 256).\n",
    "\n",
    "`dropout1`, `dropout2`: Dropout rates (0 to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6384841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Tuner\n",
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    seed=42,\n",
    "    directory='../../Tuners/student_tuner',\n",
    "    project_name='grade_classification'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146009a3",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 6) Choose the best model and run predictions\n",
    "\n",
    "Best model = the one that scored highest on validation accuracy during tuner search.\n",
    "\n",
    "Fit the best model again on full training data (20 epochs).\n",
    "\n",
    "Uuse it to predict the classes for X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce806a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Fit on full training data\n",
    "best_model.fit(X_train, y_train, epochs=20, validation_split=0.2)\n",
    "\n",
    "# Predictions\n",
    "y_pred = np.argmax(best_model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f779bd",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## 7) Run Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e5070",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "simple measure of correctness\n",
    "\n",
    "`correct predictions` / `total predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6071ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709bff7a",
   "metadata": {},
   "source": [
    "#### Precision (weighted)\n",
    "\n",
    "how many predictions were actually correct\n",
    "\n",
    "weighted adjusts for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024e94d",
   "metadata": {},
   "source": [
    "#### Recall (weighted)\n",
    "\n",
    "how many labels were correctly predicted?\n",
    "\n",
    "weighted adjusts for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb7043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d4ebf",
   "metadata": {},
   "source": [
    "#### F1 Score (weighted)\n",
    "\n",
    "harmonic mean of precision and recall\n",
    "\n",
    "weighted adjusts for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e37409",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46a7f4",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "shows real vs predicted class counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25641551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e9942",
   "metadata": {},
   "source": [
    "#### Classification Report\n",
    "\n",
    "breakdown of precision, recall, F1-Score per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c953573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff90cd",
   "metadata": {},
   "source": [
    "Metric      : Meaning\n",
    "\n",
    "Precision   : Out of all predictions for this class, how many were correct?\n",
    "\n",
    "Recall      : Out of all actual instances of this class, how many did we correctly identify?\n",
    "\n",
    "F1-Score    : Harmonic mean of Precision and Recall — balances false positives and false negatives.\n",
    "\n",
    "Support     : Number of actual test samples in each class. Shows class distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

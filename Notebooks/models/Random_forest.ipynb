{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41d7cf7",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d38ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 2. Interaction Features\n",
    "def create_interaction_features(df):\n",
    "    \"\"\"Create interaction features from the student performance dataset\"\"\"\n",
    "    \n",
    "    # Copy the dataframe to avoid modifying the original\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Parent-Study interaction: How parental support might amplify study effectiveness\n",
    "    df_new['ParentStudyInteraction'] = df_new['ParentalSupport'] * df_new['StudyTimeWeekly']\n",
    "    \n",
    "    # Extracurricular intensity: Sum of all activity participations\n",
    "    df_new['ExtracurricularIntensity'] = df_new['Sports'] + df_new['Music'] + df_new['Volunteering']\n",
    "    \n",
    "    # Academic involvement intensity: Combines study time and tutoring\n",
    "    df_new['AcademicInvolvement'] = df_new['StudyTimeWeekly'] * (1 + 0.5 * df_new['Tutoring']) # Combines study time and tutoring to reflect overall academic effort, giving 50% more weight to students with tutoring\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# 3. Ratio and Aggregate Features\n",
    "def create_ratio_aggregate_features(df):\n",
    "    \"\"\"Create ratio and aggregate features from the student performance dataset\"\"\"\n",
    "    \n",
    "    # Copy the dataframe to avoid modifying the original\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Study efficiency: ratio of study time to absences (with handling for zero absences)\n",
    "    df_new['StudyEfficiency'] = df_new['StudyTimeWeekly'] / (df_new['Absences'] + 1)\n",
    "    \n",
    "    # Academic balance: ratio of study time to extracurricular activities\n",
    "    extracurricular_count = df_new[['Sports', 'Music', 'Volunteering']].sum(axis=1)\n",
    "    # Adding 1 to avoid division by zero\n",
    "    df_new['AcademicBalance'] = df_new['StudyTimeWeekly'] / (extracurricular_count + 1)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Combined function to apply both feature engineering techniques\n",
    "def engineer_features(df):\n",
    "    \"\"\"Apply both interaction and ratio/aggregate feature engineering\"\"\"\n",
    "    df = create_interaction_features(df)\n",
    "    df = create_ratio_aggregate_features(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549a264",
   "metadata": {},
   "source": [
    "## Random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "\n",
    "df = pd.read_csv('../../Data/Student_performance_non_scaled.csv')\n",
    "\n",
    "df_engineered = engineer_features(df)\n",
    "\n",
    "# Define feature set and target\n",
    "X = df_engineered.drop('GradeClass', axis=1) \n",
    "y = df_engineered['GradeClass']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter grid (In order tO better the accuracy of the model)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300], # Number of trees in the forest; no more than 300 as it would result in too much computation\n",
    "    'max_depth': [10, 20] # Maximum depth of each tree; 10, 20 to limit complexity to prevent overfitting\n",
    "}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(\n",
    "    rf, # Base model with fixed random seed\n",
    "    param_grid=param_grid, # Hyperparameter grid to search over\n",
    "    cv=15,\n",
    "    scoring='accuracy', # Use accuracy as the metric to optimize\n",
    "    n_jobs=-1 # Use all available CPU cores to increase the speed of execution of the algorithm\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7b4d2",
   "metadata": {},
   "source": [
    "## Analyzing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07476ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 10, 'n_estimators': 200}\n",
      "\n",
      "Accuracy: 0.7157190635451505\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.22      0.32        27\n",
      "         1.0       0.57      0.52      0.55        67\n",
      "         2.0       0.51      0.58      0.55        98\n",
      "         3.0       0.50      0.56      0.53       103\n",
      "         4.0       0.91      0.90      0.90       303\n",
      "\n",
      "    accuracy                           0.72       598\n",
      "   macro avg       0.62      0.56      0.57       598\n",
      "weighted avg       0.72      0.72      0.71       598\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                   Feature  Importance\n",
      "4                 Absences    0.331720\n",
      "14         StudyEfficiency    0.227096\n",
      "11  ParentStudyInteraction    0.072432\n",
      "15         AcademicBalance    0.068928\n",
      "3          StudyTimeWeekly    0.068596\n",
      "13     AcademicInvolvement    0.068505\n",
      "6          ParentalSupport    0.031254\n",
      "2        ParentalEducation    0.024173\n",
      "0                      Age    0.023165\n",
      "7          Extracurricular    0.015782\n",
      "\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model Parameters (the hyperparameters that were applied)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../Model-Results/feature_importance_random_forest.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Save the model results\n",
    "results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'feature_importance': importance_df\n",
    "}\n",
    "\n",
    "# Export results to CSV\n",
    "importance_df.to_csv('../../Model-Results/feature_importance_random_forest.csv', index=False)\n",
    "\n",
    "print(\"\\nModel training and evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851fc21",
   "metadata": {},
   "source": [
    "# Explanation of the results\n",
    "\n",
    "## Best parameters explanation:\n",
    "  * `max_depth: 10`: Limits tree depth of each tree to 10 branches to prevent overfitting trees.\n",
    "   * `n_estimators: 200`: The number of trees, although this increases the execution time of the model, it does allow for a more accurate prediction.\n",
    "\n",
    "## Accuracy explanation:\n",
    " * Overall accuracy is **71.57%**, however the accuracy is further explored in the classification report.\n",
    "\n",
    "## Classification report explanation:\n",
    "   The classification report provides precision, recall, f1-score, and support for each class. \n",
    "\n",
    "   * **Class 0.0**:\n",
    "     * **Explanation:**: The model struggles to identify class 0.0 instances (indicated by the recall value of 22% and the f1-score of 32%), likely due to the low amount of data points that are present to train and test the model on (only 27 data points are available as indicated by the support). This is not a huge issue as this class is the top performance students thus a high accuracy here is not the biggest concern.\n",
    "\n",
    "   * **Class 1.0, 2.0 AND 3.0**:\n",
    "     * **Explanation:**: The model preforms relatively the same for these classes, with high recall (**52% for class 1.0**, **0.58 for class 2.0** and **0.56 for class 3.0**) suggesting itâ€™s not reliable for accurate predictions, this is also indicated by the **f1 score of 55% in class 1.0, 55% in class 2.0 and 53% in class 3.0**.\n",
    "\n",
    "   * **Class 4.0**:\n",
    "     * **Explanation:**: The model preforms the best here, likely due to the large number of samples. This is also the most important class to be accurate in as this class indicates the problem students. Having a high accuracy here is very beneficial. The model has an accuracy of **90% as indicated by the f1 and recall value of 0.90**\n",
    "\n",
    "## The Top 10 most important features \n",
    "This shows what features has the greatest effect on the target variable (Grade class).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cecd3bb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
